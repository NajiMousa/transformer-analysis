#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
=======================================

Ù…Ù„Ù Ù…ÙˆØ­Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…

Ø§Ù„Ù…Ø¤Ù„Ù: AI Assistant
Ø§Ù„ØªØ§Ø±ÙŠØ®: 2024
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 2.0
"""

import streamlit as st
import pandas as pd
import numpy as np
import sys
import os
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
from sklearn.linear_model import LinearRegression
from datetime import datetime, timedelta
import json
import io

class TransformerRecommendationSystem:
    def __init__(self):
        self.imbalance_threshold = 0.2  # Ø­Ø¯ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†
        self.high_imbalance_threshold = 0.4  # Ø­Ø¯ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¹Ø§Ù„ÙŠ
        self.capacity_warning_threshold = 0.85  # ØªØ­Ø°ÙŠØ± Ø¹Ù†Ø¯ 85% Ù…Ù† Ø§Ù„Ø³Ø¹Ø©
        self.capacity_critical_threshold = 0.95  # Ø®Ø·Ø± Ø¹Ù†Ø¯ 95% Ù…Ù† Ø§Ù„Ø³Ø¹Ø©
        
    def calculate_load_kva(self, row):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ù…Ù„ Ø¨Ø§Ù„Ù€ KVA"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
            ir = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± R']).replace(',', '.')) if pd.notna(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± R']) else 0
            is_val = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± S']).replace(',', '.')) if pd.notna(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± S']) else 0
            it = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± T']).replace(',', '.')) if pd.notna(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± T']) else 0
            
            # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¬Ù‡Ø¯ (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
            voltage = 400  # Ø¬Ù‡Ø¯ Ø®Ø· Ø§ÙØªØ±Ø§Ø¶ÙŠ
            avg_current = (ir + is_val + it) / 3
            load_kva = (voltage * avg_current * np.sqrt(3)) / 1000
            return load_kva
        except:
            return 0

    def calculate_imbalance(self, row):
        """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†"""
        try:
            ir = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± R']).replace(',', '.')) if pd.notna(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± R']) else 0
            is_val = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± S']).replace(',', '.')) if pd.notna(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± S']) else 0
            it = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± T']).replace(',', '.')) if pd.notna(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± T']) else 0
            
            currents = [ir, is_val, it]
            if sum(currents) == 0:
                return 0
            
            mean_current = np.mean(currents)
            if mean_current == 0:
                return 0
                
            std_current = np.std(currents)
            imbalance = std_current / mean_current
            return imbalance
        except:
            return 0

    def add_season(self, df):
        """Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙˆØ³Ù… Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'] = pd.to_datetime(df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], errors='coerce')
        df['Ø§Ù„Ù…ÙˆØ³Ù…'] = df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'].dt.month.apply(
            lambda m: "Ø´ØªÙˆÙŠ" if m in [12, 1, 2, 3] else ("ØµÙŠÙÙŠ" if m in [6, 7, 8] else "Ø§Ù†ØªÙ‚Ø§Ù„ÙŠ")
        )
        return df

    def prepare_data(self, loads_df):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
        # ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        loads_df = self.add_season(loads_df)
        loads_df['Load_kVA'] = loads_df.apply(self.calculate_load_kva, axis=1)
        loads_df['Imbalance'] = loads_df.apply(self.calculate_imbalance, axis=1)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ù†Ø©
        loads_df['Ø§Ù„Ø³Ù†Ø©'] = loads_df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'].dt.year
        
        return loads_df

    def analyze_feeder_historical(self, feeder_data, feeder_name):
        """ØªØ­Ù„ÙŠÙ„ ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ø³ÙƒÙŠÙ†Ø© Ù…Ø¹ÙŠÙ†Ø©"""
        analysis = {
            'feeder_name': feeder_name,
            'current_status': 'Ø¬ÙŠØ¯Ø©',
            'historical_pattern': 'Ù…Ø³ØªÙ‚Ø±Ø©',
            'seasonal_behavior': {},
            'trend': 'Ù…Ø³ØªÙ‚Ø±',
            'recommendations': []
        }
        
        if feeder_data.empty:
            return analysis
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ
        seasonal_imbalance = feeder_data.groupby('Ø§Ù„Ù…ÙˆØ³Ù…')['Imbalance'].mean()
        
        # Ø£Ø­Ø¯Ø« Ø³Ù†Ø©
        latest_year = feeder_data['Ø§Ù„Ø³Ù†Ø©'].max()
        current_data = feeder_data[feeder_data['Ø§Ù„Ø³Ù†Ø©'] == latest_year]
        current_imbalance = current_data['Imbalance'].mean()
        
        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
        historical_data = feeder_data[feeder_data['Ø§Ù„Ø³Ù†Ø©'] < latest_year]
        historical_imbalance = historical_data['Imbalance'].mean() if not historical_data.empty else 0
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        if current_imbalance > self.high_imbalance_threshold:
            analysis['current_status'] = 'Ø³ÙŠØ¦Ø©'
        elif current_imbalance > self.imbalance_threshold:
            analysis['current_status'] = 'ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ù‚Ø¨Ø©'
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù…Ø· Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        if not historical_data.empty:
            if historical_imbalance > self.imbalance_threshold and current_imbalance > self.imbalance_threshold:
                analysis['historical_pattern'] = 'Ù…Ø²Ù…Ù†Ø©'
            elif historical_imbalance <= self.imbalance_threshold and current_imbalance > self.imbalance_threshold:
                analysis['historical_pattern'] = 'Ù…Ø´ÙƒÙ„Ø© Ø¬Ø¯ÙŠØ¯Ø©'
            elif historical_imbalance > self.imbalance_threshold and current_imbalance <= self.imbalance_threshold:
                analysis['historical_pattern'] = 'Ù…Ø­Ø³Ù†Ø©'
        
        # Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ
        for season, imbalance in seasonal_imbalance.items():
            if imbalance > self.imbalance_threshold:
                analysis['seasonal_behavior'][season] = 'ØºÙŠØ± Ù…ØªØ²Ù†Ø©'
            else:
                analysis['seasonal_behavior'][season] = 'Ù…ØªØ²Ù†Ø©'
        
        return analysis

    def generate_feeder_recommendations(self, feeder_analysis):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù„Ø³ÙƒÙŠÙ†Ø© Ù…Ø¹ÙŠÙ†Ø©"""
        recommendations = []
        feeder_name = feeder_analysis['feeder_name']
        
        # ØªÙˆØµÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®
        if feeder_analysis['current_status'] == 'Ø³ÙŠØ¦Ø©':
            if feeder_analysis['historical_pattern'] == 'Ù…Ø²Ù…Ù†Ø©':
                recommendations.append({
                    "title": f"Ù…Ø´ÙƒÙ„Ø© Ù…Ø²Ù…Ù†Ø© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ù…Ø²Ù…Ù† ÙŠØªØ·Ù„Ø¨ ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ",
                    "severity": "error",
                    "action": f"Ø¥Ø±Ø³Ø§Ù„ ÙØ±ÙŠÙ‚ ÙÙ†ÙŠ Ù…ØªØ®ØµØµ Ù„Ù„ÙƒØ´Ù Ø§Ù„Ø´Ø§Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ù…Ø§Ù„",
                    "due_in_days": 3,
                    "status": "Ø¬Ø¯ÙŠØ¯",
                    "priority": "Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹"
                })
            else:
                recommendations.append({
                    "title": f"Ù…Ø´ÙƒÙ„Ø© Ø¬Ø¯ÙŠØ¯Ø© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} ØªØ¸Ù‡Ø± Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø¬Ø¯ÙŠØ¯ ÙŠØªØ·Ù„Ø¨ ØªØ­Ù‚ÙŠÙ‚ Ø³Ø±ÙŠØ¹",
                    "severity": "error",
                    "action": f"ÙØ­Øµ Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø£Ùˆ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "due_in_days": 5,
                    "status": "Ø¬Ø¯ÙŠØ¯",
                    "priority": "Ø¹Ø§Ù„ÙŠØ©"
                })
                
        elif feeder_analysis['current_status'] == 'ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ù‚Ø¨Ø©':
            if feeder_analysis['historical_pattern'] == 'Ù…Ø²Ù…Ù†Ø©':
                recommendations.append({
                    "title": f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¯ÙˆØ±ÙŠØ© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} ØªØ­Ø³Ù†Øª Ù„ÙƒÙ† ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø³ØªÙ…Ø±Ø© Ø¨Ø³Ø¨Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø²Ù…Ù†",
                    "severity": "warning",
                    "action": f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© Ù„Ù„Ø£Ø­Ù…Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} Ù…Ø¹ ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø±ÙŠ",
                    "due_in_days": 7,
                    "status": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                    "priority": "Ù…ØªÙˆØ³Ø·Ø©"
                })
            else:
                recommendations.append({
                    "title": f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø­ØªØ±Ø§Ø²ÙŠØ© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} ØªØ¸Ù‡Ø± Ø¨Ø¯Ø§ÙŠØ© Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† ÙŠØªØ·Ù„Ø¨ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©",
                    "severity": "warning",
                    "action": f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ù†ØµÙ Ø´Ù‡Ø±ÙŠØ© ÙˆÙ…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "due_in_days": 14,
                    "status": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                    "priority": "Ù…ØªÙˆØ³Ø·Ø©"
                })
                
        else:  # Ø­Ø§Ù„Ø© Ø¬ÙŠØ¯Ø©
            if feeder_analysis['historical_pattern'] == 'Ù…Ø­Ø³Ù†Ø©':
                recommendations.append({
                    "title": f"ØªØ­Ø³Ù† Ù…Ù„Ø­ÙˆØ¸ - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} Ø£Ø¸Ù‡Ø±Øª ØªØ­Ø³Ù†Ø§Ù‹ ÙƒØ¨ÙŠØ±Ø§Ù‹ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©",
                    "severity": "success",
                    "action": f"Ù…ÙˆØ§ØµÙ„Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¬ÙŠØ¯ Ù„Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "due_in_days": 30,
                    "status": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                    "priority": "Ù…Ù†Ø®ÙØ¶Ø©"
                })
            elif feeder_analysis['historical_pattern'] == 'Ù…Ø²Ù…Ù†Ø©':
                recommendations.append({
                    "title": f"Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆÙ‚Ø§Ø¦ÙŠØ© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} Ø¬ÙŠØ¯Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ Ù„ÙƒÙ† Ù„Ù‡Ø§ ØªØ§Ø±ÙŠØ® ÙÙŠ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†",
                    "severity": "info",
                    "action": f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¯ÙˆØ±ÙŠØ© ÙƒÙ„ Ø´Ù‡Ø±ÙŠÙ† Ù„Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¬ÙŠØ¯",
                    "due_in_days": 60,
                    "status": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                    "priority": "Ù…Ù†Ø®ÙØ¶Ø©"
                })
            else:
                recommendations.append({
                    "title": f"Ø£Ø¯Ø§Ø¡ Ù…Ø³ØªÙ‚Ø± - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} ØªØ¹Ù…Ù„ Ø¨ÙƒÙØ§Ø¡Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆÙ„Ø§ ØªØ­ØªØ§Ø¬ ØªØ¯Ø®Ù„",
                    "severity": "success",
                    "action": f"Ù…Ø±Ø§Ù‚Ø¨Ø© Ø±Ø¨Ø¹ Ø³Ù†ÙˆÙŠØ© Ø±ÙˆØªÙŠÙ†ÙŠØ© Ù„Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                    "due_in_days": 90,
                    "status": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                    "priority": "Ù…Ù†Ø®ÙØ¶Ø©"
                })
        
        # ØªÙˆØµÙŠØ§Øª Ù…ÙˆØ³Ù…ÙŠØ©
        seasonal_issues = []
        for season, status in feeder_analysis['seasonal_behavior'].items():
            if status == 'ØºÙŠØ± Ù…ØªØ²Ù†Ø©':
                seasonal_issues.append(season)
        
        if seasonal_issues:
            recommendations.append({
                "title": f"Ù…Ø´ÙƒÙ„Ø© Ù…ÙˆØ³Ù…ÙŠØ© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}",
                "message": f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} ØªØ¸Ù‡Ø± Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† ÙÙŠ ÙØµÙˆÙ„: {', '.join(seasonal_issues)}",
                "severity": "warning",
                "action": f"ØªØ­Ø¶ÙŠØ± Ø®Ø·Ø© Ù…ÙˆØ³Ù…ÙŠØ© Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} Ù‚Ø¨Ù„ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©",
                "due_in_days": 30,
                "status": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                "priority": "Ù…ØªÙˆØ³Ø·Ø©"
            })
        
        return recommendations

    def analyze_transformer_capacity(self, loads_df, transformer_capacity):
        """ØªØ­Ù„ÙŠÙ„ Ø³Ø¹Ø© Ø§Ù„Ù…Ø­ÙˆÙ„"""
        capacity_analysis = {
            'seasonal_loads': {},
            'capacity_utilization': {},
            'predictions': {},
            'recommendations': []
        }
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ Ù„Ù„Ø£Ø­Ù…Ø§Ù„
        seasonal_loads = loads_df.groupby('Ø§Ù„Ù…ÙˆØ³Ù…')['Load_kVA'].agg(['mean', 'max']).to_dict()
        
        for season in ['Ø´ØªÙˆÙŠ', 'ØµÙŠÙÙŠ']:
            if season in seasonal_loads['mean']:
                avg_load = seasonal_loads['mean'][season]
                max_load = seasonal_loads['max'][season]
                
                capacity_analysis['seasonal_loads'][season] = {
                    'average': avg_load,
                    'maximum': max_load,
                    'utilization': (avg_load / transformer_capacity) * 100,
                    'max_utilization': (max_load / transformer_capacity) * 100
                }
                
                # ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø³Ø¹Ø©
                if max_load > transformer_capacity:
                    capacity_analysis['recommendations'].append({
                        "title": f"ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø³Ø¹Ø© - ÙØµÙ„ {season}",
                        "message": f"Ø§Ù„Ù…Ø­ÙˆÙ„ ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø³Ø¹Ø© Ø§Ù„Ù…Ù‚Ø±Ø±Ø© ({transformer_capacity} KVA) ÙÙŠ ÙØµÙ„ {season} Ø¨Ø­Ù…ÙˆÙ„Ø© Ù‚ØµÙˆÙ‰ {max_load:.1f} KVA",
                        "severity": "error",
                        "action": "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ø¬Ù„Ø© Ù„Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø£Ùˆ ØªØ±Ù‚ÙŠØ© Ø§Ù„Ù…Ø­ÙˆÙ„",
                        "due_in_days": 7,
                        "status": "Ø¬Ø¯ÙŠØ¯",
                        "priority": "Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹"
                    })
                elif avg_load > transformer_capacity * self.capacity_critical_threshold:
                    capacity_analysis['recommendations'].append({
                        "title": f"Ø§Ù‚ØªØ±Ø§Ø¨ Ù…Ù† Ø§Ù„Ø³Ø¹Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ - ÙØµÙ„ {season}",
                        "message": f"Ø§Ù„Ù…Ø­ÙˆÙ„ ÙŠÙ‚ØªØ±Ø¨ Ù…Ù† Ø§Ù„Ø³Ø¹Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ ÙÙŠ ÙØµÙ„ {season} Ø¨Ù…ØªÙˆØ³Ø· Ø­Ù…ÙˆÙ„Ø© {avg_load:.1f} KVA",
                        "severity": "warning",
                        "action": "Ù…Ø±Ø§Ù‚Ø¨Ø© ÙŠÙˆÙ…ÙŠØ© ÙˆØ¥Ø¹Ø¯Ø§Ø¯ Ø®Ø·Ø© Ø·ÙˆØ§Ø±Ø¦ Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ù…Ø§Ù„",
                        "due_in_days": 14,
                        "status": "Ù…Ø±Ø§Ù‚Ø¨Ø©",
                        "priority": "Ø¹Ø§Ù„ÙŠØ©"
                    })
                elif avg_load < transformer_capacity * 0.3:
                    capacity_analysis['recommendations'].append({
                        "title": f"Ø§Ø³ØªØºÙ„Ø§Ù„ Ù…Ù†Ø®ÙØ¶ Ù„Ù„Ø³Ø¹Ø© - ÙØµÙ„ {season}",
                        "message": f"Ø§Ù„Ù…Ø­ÙˆÙ„ Ù…Ø³ØªØºÙ„ Ø¨Ø£Ù‚Ù„ Ù…Ù† 30% Ù…Ù† Ø§Ù„Ø³Ø¹Ø© ÙÙŠ ÙØµÙ„ {season}",
                        "severity": "info",
                        "action": "Ø¯Ø±Ø§Ø³Ø© Ø¥Ù…ÙƒØ§Ù†ÙŠØ© ØªÙˆØµÙŠÙ„ Ø£Ø­Ù…Ø§Ù„ Ø¥Ø¶Ø§ÙÙŠØ© Ø£Ùˆ ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù…Ø­ÙˆÙ„",
                        "due_in_days": 60,
                        "status": "Ø¯Ø±Ø§Ø³Ø©",
                        "priority": "Ù…Ù†Ø®ÙØ¶Ø©"
                    })
        
        return capacity_analysis

    def generate_predictive_analysis(self, loads_df, transformer_capacity):
        """ØªØ­Ù„ÙŠÙ„ ØªÙ†Ø¨Ø¤ÙŠ Ù„Ù„Ø£Ø­Ù…Ø§Ù„"""
        predictions = {}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ†Ø¨Ø¤
        df_predict = loads_df.dropna(subset=['Load_kVA']).copy()
        if df_predict.empty:
            return predictions
            
        df_predict = df_predict.sort_values('ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³')
        df_predict['Days'] = (df_predict['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'] - df_predict['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'].min()).dt.days
        
        X = df_predict[['Days']].values
        y = df_predict['Load_kVA'].values
        
        try:
            model = LinearRegression()
            model.fit(X, y)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ù„ÙØªØ±Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
            last_day = df_predict['Days'].max()
            future_periods = [30, 90, 180, 365]  # Ø´Ù‡Ø±ØŒ 3 Ø£Ø´Ù‡Ø±ØŒ 6 Ø£Ø´Ù‡Ø±ØŒ Ø³Ù†Ø©
            period_names = ["Ø´Ù‡Ø±", "3 Ø£Ø´Ù‡Ø±", "6 Ø£Ø´Ù‡Ø±", "Ø³Ù†Ø©"]
            
            for period, name in zip(future_periods, period_names):
                future_load = model.predict([[last_day + period]])[0]
                predictions[name] = {
                    'predicted_load': future_load,
                    'utilization': (future_load / transformer_capacity) * 100,
                    'risk_level': self.assess_risk_level(future_load, transformer_capacity)
                }
        except:
            pass
            
        return predictions

    def assess_risk_level(self, predicted_load, capacity):
        """ØªÙ‚ÙŠÙŠÙ… Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
        utilization = predicted_load / capacity
        
        if utilization > 1.0:
            return "Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹"
        elif utilization > 0.95:
            return "Ø¹Ø§Ù„ÙŠ"
        elif utilization > 0.85:
            return "Ù…ØªÙˆØ³Ø·"
        elif utilization > 0.7:
            return "Ù…Ù†Ø®ÙØ¶"
        else:
            return "Ø¢Ù…Ù†"

    def generate_comprehensive_recommendations(self, loads_df, transformer_info, selected_transformer_id=None):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù…Ø­ÙˆÙ„"""
        
        all_recommendations = []
        executive_summary = []
        
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        loads_df = self.prepare_data(loads_df)
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯
        if selected_transformer_id:
            loads_df = loads_df[loads_df['Transformer_id'] == selected_transformer_id]
        
        if loads_df.empty:
            return all_recommendations, executive_summary
        
        # Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„
        transformer_capacity = None
        if isinstance(transformer_info, pd.DataFrame):
            transformer_capacity = transformer_info['Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„ KVA'].iloc[0] if 'Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„ KVA' in transformer_info.columns else 500
        elif isinstance(transformer_info, dict):
            transformer_capacity = transformer_info.get('Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„ KVA', 500)
        else:
            transformer_capacity = 500  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        
        # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†
        st.subheader("ğŸ”Œ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†")
        feeders = loads_df['Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©'].unique()
        feeder_analyses = {}
        
        for feeder in feeders:
            feeder_data = loads_df[loads_df['Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©'] == feeder].copy()
            feeder_analysis = self.analyze_feeder_historical(feeder_data, feeder)
            feeder_analyses[feeder] = feeder_analysis
            
            # ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø³ÙƒÙŠÙ†Ø©
            feeder_recs = self.generate_feeder_recommendations(feeder_analysis)
            all_recommendations.extend(feeder_recs)
            
            # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ
            if feeder_analysis['current_status'] != 'Ø¬ÙŠØ¯Ø©':
                executive_summary.append(f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder}: {feeder_analysis['current_status']} ({feeder_analysis['historical_pattern']})")
        
        # 2. ØªØ­Ù„ÙŠÙ„ Ø³Ø¹Ø© Ø§Ù„Ù…Ø­ÙˆÙ„
        st.subheader("âš¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¹Ø©")
        capacity_analysis = self.analyze_transformer_capacity(loads_df, transformer_capacity)
        all_recommendations.extend(capacity_analysis['recommendations'])
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¹Ø© Ù„Ù„Ù…Ù„Ø®Øµ
        for season, data in capacity_analysis['seasonal_loads'].items():
            if data['max_utilization'] > 100:
                executive_summary.append(f"ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø³Ø¹Ø© ÙÙŠ ÙØµÙ„ {season} ({data['max_utilization']:.1f}%)")
            elif data['utilization'] < 30:
                executive_summary.append(f"Ø§Ø³ØªØºÙ„Ø§Ù„ Ù…Ù†Ø®ÙØ¶ ÙÙŠ ÙØµÙ„ {season} ({data['utilization']:.1f}%)")
        
        # 3. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠ
        st.subheader("ğŸ”® Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠ")
        predictions = self.generate_predictive_analysis(loads_df, transformer_capacity)
        
        for period, pred_data in predictions.items():
            risk = pred_data['risk_level']
            if risk in ["Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹", "Ø¹Ø§Ù„ÙŠ"]:
                all_recommendations.append({
                    "title": f"ØªØ­Ø°ÙŠØ± ØªÙ†Ø¨Ø¤ÙŠ - Ø®Ù„Ø§Ù„ {period}",
                    "message": f"Ø§Ù„ØªÙ†Ø¨Ø¤ ÙŠØ´ÙŠØ± Ù„ØªØ¬Ø§ÙˆØ² Ù…Ø­ØªÙ…Ù„ Ù„Ù„Ø³Ø¹Ø© Ø®Ù„Ø§Ù„ {period} (Ù…Ø®Ø§Ø·Ø± {risk})",
                    "severity": "error" if risk == "Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹" else "warning",
                    "action": "Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø·Ø© ÙˆÙ‚Ø§Ø¦ÙŠØ© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø³Ø¹Ø© Ø£Ùˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ù…Ø§Ù„",
                    "due_in_days": 30 if period == "Ø´Ù‡Ø±" else 60,
                    "status": "ØªØ®Ø·ÙŠØ·",
                    "priority": "Ø¹Ø§Ù„ÙŠØ©"
                })
                executive_summary.append(f"ØªÙˆÙ‚Ø¹ Ù…Ø´Ø§ÙƒÙ„ Ø®Ù„Ø§Ù„ {period}")
        
        # 4. ØªÙˆØµÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
        advanced_recs = self.generate_advanced_recommendations(loads_df, feeder_analyses, capacity_analysis)
        all_recommendations.extend(advanced_recs)
        
        # 5. Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if executive_summary:
            final_summary = self.create_executive_summary(executive_summary, all_recommendations)
            all_recommendations.append(final_summary)
        
        return all_recommendations, feeder_analyses, capacity_analysis, predictions

    def generate_advanced_recommendations(self, loads_df, feeder_analyses, capacity_analysis):
        """ØªÙˆØµÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„"""
        advanced_recs = []
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ† ÙˆÙ…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³Ø¹Ø©
        problematic_feeders = [f for f, analysis in feeder_analyses.items() 
                             if analysis['current_status'] in ['Ø³ÙŠØ¦Ø©', 'ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ù‚Ø¨Ø©']]
        
        seasonal_capacity_issues = [season for season, data in capacity_analysis['seasonal_loads'].items()
                                  if data.get('max_utilization', 0) > 95]
        
        if problematic_feeders and seasonal_capacity_issues:
            advanced_recs.append({
                "title": "ØªØ±Ø§Ø¨Ø· Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ† ÙˆØ§Ù„Ø³Ø¹Ø©",
                "message": f"Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³Ø¹Ø© ÙÙŠ {', '.join(seasonal_capacity_issues)} Ù‚Ø¯ ØªØ±ØªØ¨Ø· Ø¨Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†: {', '.join(problematic_feeders)}",
                "severity": "warning",
                "action": "Ø¯Ø±Ø§Ø³Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ† ÙˆØªØ¬Ø§ÙˆØ² Ø§Ù„Ø³Ø¹Ø© ÙˆØ¥Ø¹Ø¯Ø§Ø¯ Ø®Ø·Ø© Ù…ØªÙƒØ§Ù…Ù„Ø©",
                "due_in_days": 21,
                "status": "Ø¯Ø±Ø§Ø³Ø©",
                "priority": "Ø¹Ø§Ù„ÙŠØ©"
            })
        
        # ØªÙˆØµÙŠØ© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ©
        maintenance_priority = "Ø¹Ø§Ù„ÙŠØ©" if problematic_feeders else "Ù…ØªÙˆØ³Ø·Ø©"
        maintenance_days = 30 if problematic_feeders else 90
        
        advanced_recs.append({
            "title": "Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ©",
            "message": f"ÙˆØ¶Ø¹ Ø¨Ø±Ù†Ø§Ù…Ø¬ ØµÙŠØ§Ù†Ø© Ø¯ÙˆØ±ÙŠØ© Ù„Ù„Ù…Ø­ÙˆÙ„ Ø¨Ø£ÙˆÙ„ÙˆÙŠØ© {maintenance_priority}",
            "severity": "info",
            "action": "Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ ØµÙŠØ§Ù†Ø© Ø´Ø§Ù…Ù„ ÙŠØ´Ù…Ù„ ÙØ­Øµ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ† ÙˆØ§Ù„Ø­Ù…ÙˆÙ„Ø§Øª ÙˆØ§Ù„Ù…Ø¹Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ù‚ÙŠØ©",
            "due_in_days": maintenance_days,
            "status": "ØªØ®Ø·ÙŠØ·",
            "priority": maintenance_priority
        })
        
        return advanced_recs

    def create_executive_summary(self, summary_points, all_recommendations):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        error_count = len([r for r in all_recommendations if r.get('severity') == 'error'])
        warning_count = len([r for r in all_recommendations if r.get('severity') == 'warning'])
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        if error_count > 0:
            overall_priority = "Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹"
            overall_status = "ÙŠØªØ·Ù„Ø¨ ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ"
        elif warning_count > 2:
            overall_priority = "Ø¹Ø§Ù„ÙŠØ©"
            overall_status = "ÙŠØªØ·Ù„Ø¨ Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…ÙƒØ«ÙØ©"
        elif warning_count > 0:
            overall_priority = "Ù…ØªÙˆØ³Ø·Ø©"
            overall_status = "ÙŠØªØ·Ù„Ø¨ Ù…Ø±Ø§Ù‚Ø¨Ø©"
        else:
            overall_priority = "Ù…Ù†Ø®ÙØ¶Ø©"
            overall_status = "ÙˆØ¶Ø¹ Ù…Ø³ØªÙ‚Ø±"
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© (Ø£Ù‚Ù„ Ù…Ù‡Ù„Ø© Ù…Ù† Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø­Ø±Ø¬Ø©)
        critical_recs = [r for r in all_recommendations if r.get('severity') in ['error', 'warning']]
        overall_due_days = min([r['due_in_days'] for r in critical_recs], default=90)
        
        summary_message = f"Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù…Ø­ÙˆÙ„: {overall_status}. "
        summary_message += f"Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {' â€” '.join(summary_points[:3])}. " if summary_points else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø´Ø§ÙƒÙ„ Ø­Ø±Ø¬Ø©. "
        summary_message += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {len(all_recommendations)} ({error_count} Ø­Ø±Ø¬Ø©ØŒ {warning_count} ØªØ­Ø°ÙŠØ±ÙŠØ©)"
        
        return {
            "title": "ğŸ“‹ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ",
            "message": summary_message,
            "severity": "error" if error_count > 0 else ("warning" if warning_count > 0 else "info"),
            "action": f"ØªÙ†ÙÙŠØ° Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©ØŒ Ø¨Ø¯Ø¡Ø§Ù‹ Ù…Ù† Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø­Ø±Ø¬Ø©",
            "due_in_days": overall_due_days,
            "status": "Ø¬Ø¯ÙŠØ¯",
            "priority": overall_priority,
            "statistics": {
                "total_recommendations": len(all_recommendations),
                "critical": error_count,
                "warnings": warning_count,
                "overall_status": overall_status
            }
        }

    def create_data_visualization(self, loads_df, feeder_name=None):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        
        if feeder_name:
            data = loads_df[loads_df['Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©'] == feeder_name].copy()
            title_suffix = f"- Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}"
        else:
            data = loads_df.copy()
            title_suffix = "- Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†"
        
        visualizations = {}
        
        # 1. Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†
        if not data.empty:
            fig_imbalance = px.line(
                data, 
                x='ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³', 
                y='Imbalance', 
                color='Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©',
                title=f'ØªØ·ÙˆØ± Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† {title_suffix}',
                labels={'Imbalance': 'Ù†Ø³Ø¨Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': 'Ø§Ù„ØªØ§Ø±ÙŠØ®'}
            )
            fig_imbalance.add_hline(y=0.2, line_dash="dash", line_color="orange", 
                                  annotation_text="Ø­Ø¯ Ø§Ù„ØªØ­Ø°ÙŠØ± (0.2)")
            fig_imbalance.add_hline(y=0.4, line_dash="dash", line_color="red", 
                                  annotation_text="Ø­Ø¯ Ø§Ù„Ø®Ø·Ø± (0.4)")
            visualizations['imbalance_trend'] = fig_imbalance
            
            # 2. Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø£Ø­Ù…Ø§Ù„
            fig_load = px.line(
                data,
                x='ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³',
                y='Load_kVA',
                color='Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©',
                title=f'ØªØ·ÙˆØ± Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† {title_suffix}',
                labels={'Load_kVA': 'Ø§Ù„Ø­Ù…Ù„ (KVA)', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': 'Ø§Ù„ØªØ§Ø±ÙŠØ®'}
            )
            visualizations['load_trend'] = fig_load
            
            # 3. Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø©
            if feeder_name:
                # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ø³Ù…
                currents_data = []
                for _, row in data.iterrows():
                    try:
                        ir = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± R']).replace(',', '.'))
                        is_val = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± S']).replace(',', '.'))
                        it = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± T']).replace(',', '.'))
                        
                        currents_data.extend([
                            {'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': row['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], 'Ø§Ù„ÙØ§Ø²': 'R', 'Ø§Ù„ØªÙŠØ§Ø±': ir},
                            {'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': row['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], 'Ø§Ù„ÙØ§Ø²': 'S', 'Ø§Ù„ØªÙŠØ§Ø±': is_val},
                            {'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': row['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], 'Ø§Ù„ÙØ§Ø²': 'T', 'Ø§Ù„ØªÙŠØ§Ø±': it}
                        ])
                    except:
                        continue
                
                if currents_data:
                    currents_df = pd.DataFrame(currents_data)
                    fig_phases = px.line(
                        currents_df,
                        x='ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³',
                        y='Ø§Ù„ØªÙŠØ§Ø±',
                        color='Ø§Ù„ÙØ§Ø²',
                        title=f'ØªØ·ÙˆØ± Ø§Ù„ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name}',
                        labels={'Ø§Ù„ØªÙŠØ§Ø±': 'Ø§Ù„ØªÙŠØ§Ø± (Ø£Ù…Ø¨ÙŠØ±)', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': 'Ø§Ù„ØªØ§Ø±ÙŠØ®'}
                    )
                    visualizations['phases_trend'] = fig_phases
        
        return visualizations

    def save_recommendations_state(self, recommendations, file_path="recommendations_state.json"):
        """Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø­ÙØ¸
            state_data = {
                "timestamp": datetime.now().isoformat(),
                "recommendations": []
            }
            
            for rec in recommendations:
                state_data["recommendations"].append({
                    "id": hash(rec['title'] + rec['message']),  # Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯
                    "title": rec['title'],
                    "message": rec['message'],
                    "severity": rec['severity'],
                    "action": rec['action'],
                    "due_in_days": rec['due_in_days'],
                    "status": rec.get('status', 'Ø¬Ø¯ÙŠØ¯'),
                    "priority": rec.get('priority', 'Ù…ØªÙˆØ³Ø·Ø©'),
                    "created_date": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat()
                })
            
            # Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù JSON
            print("ğŸ“‚ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø©:", file_path)

            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, ensure_ascii=False, indent=2)
            
            return True
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª: {str(e)}")
            return False

    def load_recommendations_state(self, file_path="recommendations_state.json"):
        """ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©"""
        try:
            if Path(file_path).exists():
                print("ğŸ“‚ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø©:", file_path)

                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return None
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª: {str(e)}")
            return None

    def update_recommendation_status(self, rec_id, new_status, file_path="recommendations_state.json"):
        """ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© ØªÙˆØµÙŠØ© Ù…Ø¹ÙŠÙ†Ø©"""
        try:
            state_data = self.load_recommendations_state(file_path)
            if state_data:
                for rec in state_data["recommendations"]:
                    if rec["id"] == rec_id:
                        rec["status"] = new_status
                        rec["last_updated"] = datetime.now().isoformat()
                        break
                
                # Ø­ÙØ¸ Ø§Ù„ØªØ­Ø¯ÙŠØ«
                print("ğŸ“‚ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø©:", file_path)

                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(state_data, f, ensure_ascii=False, indent=2)
                return True
            return False
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ©: {str(e)}")
            return False


def display_enhanced_recommendations(recommendations, feeder_analyses=None, capacity_analysis=None, predictions=None):
    """Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø·ÙˆØ±Ø© Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª ØªÙØ§Ø¹Ù„ÙŠØ©"""
    
    severity_styles = {
        "error":   {"icon": "ğŸš¨", "bg": "#ffebee", "border": "#f44336", "color": "#c62828"},
        "warning": {"icon": "âš ï¸", "bg": "#fff8e1", "border": "#ff9800", "color": "#f57c00"},
        "success": {"icon": "âœ…", "bg": "#e8f5e9", "border": "#4caf50", "color": "#2e7d32"},
        "info":    {"icon": "â„¹ï¸", "bg": "#e3f2fd", "border": "#2196f3", "color": "#1565c0"},
    }
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
    error_count = len([r for r in recommendations if r.get('severity') == 'error'])
    warning_count = len([r for r in recommendations if r.get('severity') == 'warning'])
    success_count = len([r for r in recommendations if r.get('severity') == 'success'])
    info_count = len([r for r in recommendations if r.get('severity') == 'info'])
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸš¨ Ø­Ø±Ø¬Ø©", error_count)
    with col2:
        st.metric("âš ï¸ ØªØ­Ø°ÙŠØ±ÙŠØ©", warning_count)
    with col3:
        st.metric("âœ… Ø¬ÙŠØ¯Ø©", success_count)
    with col4:
        st.metric("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ©", info_count)
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª
    st.subheader("ğŸ” ÙÙ„ØªØ±Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª")
    severity_filter = st.multiselect(
        "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª:",
        ["error", "warning", "success", "info"],
        default=["error", "warning"],
        format_func=lambda x: {"error": "ğŸš¨ Ø­Ø±Ø¬Ø©", "warning": "âš ï¸ ØªØ­Ø°ÙŠØ±ÙŠØ©", 
                              "success": "âœ… Ø¬ÙŠØ¯Ø©", "info": "â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ©"}[x]
    )
    
    # Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…ÙÙ„ØªØ±Ø©
    filtered_recommendations = [r for r in recommendations if r.get('severity') in severity_filter]
    
    for i, rec in enumerate(filtered_recommendations):
        style = severity_styles.get(rec.get('severity', 'info'), severity_styles["info"])
        
        with st.container():
            # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ø±Ø³Ø§Ù„Ø©
            st.markdown(
                f"""
                <div style="
                    background: linear-gradient(135deg, {style['bg']} 0%, white 100%);
                    border-left: 6px solid {style['border']};
                    padding: 20px;
                    margin: 15px 0;
                    border-radius: 12px;
                    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
                    color: {style['color']};
                    font-family: 'Segoe UI', Arial, sans-serif;">
                    
                    <div style="display: flex; align-items: center; margin-bottom: 10px;">
                        <span style="font-size: 24px; margin-right: 10px;">{style['icon']}</span>
                        <h3 style="margin: 0; color: {style['color']}; font-size: 20px; font-weight: bold;">
                            {rec['title']}
                        </h3>
                    </div>
                    
                    <p style="margin: 10px 0; font-size: 16px; line-height: 1.6; color: #333;">
                        {rec['message']}
                    </p>
                </div>
                """,
                unsafe_allow_html=True
            )
            
            # ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø·ÙŠ
            with st.expander("ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙˆØµÙŠØ©", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**ğŸ›  Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**")
                    st.write(rec['action'])
                    
                    st.markdown(f"**â° Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©:**")
                    st.write(f"{rec['due_in_days']} ÙŠÙˆÙ…")
                
                with col2:
                    st.markdown(f"**ğŸ“Š Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©:**")
                    priority = rec.get('priority', 'Ù…ØªÙˆØ³Ø·Ø©')
                    priority_color = {"Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹": "ğŸ”´", "Ø¹Ø§Ù„ÙŠØ©": "ğŸŸ ", "Ù…ØªÙˆØ³Ø·Ø©": "ğŸŸ¡", "Ù…Ù†Ø®ÙØ¶Ø©": "ğŸŸ¢"}
                    st.write(f"{priority_color.get(priority, 'ğŸŸ¡')} {priority}")
                    
                    # Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø©
                    st.markdown(f"**ğŸ“Œ Ø§Ù„Ø­Ø§Ù„Ø©:**")
                    current_status = rec.get('status', 'Ø¬Ø¯ÙŠØ¯')
                    new_status = st.selectbox(
                        "ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©:",
                        ["Ø¬Ø¯ÙŠØ¯", "Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°", "Ù…Ø±Ø§Ù‚Ø¨Ø©", "ØªÙ… Ø§Ù„Ø­Ù„", "Ù…Ø¤Ø¬Ù„"],
                        index=["Ø¬Ø¯ÙŠØ¯", "Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°", "Ù…Ø±Ø§Ù‚Ø¨Ø©", "ØªÙ… Ø§Ù„Ø­Ù„", "Ù…Ø¤Ø¬Ù„"].index(current_status),
                        key=f"status_{i}"
                    )
                    
                    if new_status != current_status:
                        st.success(f"ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø¥Ù„Ù‰: {new_status}")
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ø§Ù†Ø¯Ø© Ø¥Ø°Ø§ ØªÙˆÙØ±Øª
                if 'examples' in rec and rec['examples']:
                    st.markdown("**ğŸ“Š Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**")
                    st.dataframe(pd.DataFrame(rec['examples']))
            
            # Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª
            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button(f"ğŸ“Š Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", key=f"show_data_{i}"):
                    st.session_state[f"show_viz_{i}"] = True
            
            with col2:
                if st.button(f"ğŸ“ Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ø§Ø­Ø¸Ø©", key=f"add_note_{i}"):
                    st.session_state[f"show_note_{i}"] = True
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
            if st.session_state.get(f"show_viz_{i}", False):
                st.markdown("### ğŸ“Š Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©")
                # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
                st.info("Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ù‡Ù†Ø§")
                
                if st.button(f"Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", key=f"hide_viz_{i}"):
                    st.session_state[f"show_viz_{i}"] = False
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª
            if st.session_state.get(f"show_note_{i}", False):
                note = st.text_area(f"Ø£Ø¶Ù Ù…Ù„Ø§Ø­Ø¸Ø© Ù„Ù„ØªÙˆØµÙŠØ©:", key=f"note_text_{i}")
                if st.button(f"Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©", key=f"save_note_{i}"):
                    st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ø¨Ù†Ø¬Ø§Ø­")
                    st.session_state[f"show_note_{i}"] = False
    
    # Ù…Ù„Ø®Øµ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    if filtered_recommendations:
        st.markdown("---")
        st.subheader("ğŸ“… Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø¨Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        actions_data = []
        for rec in filtered_recommendations:
            actions_data.append({
                "Ø§Ù„ØªÙˆØµÙŠØ©": rec['title'][:50] + "..." if len(rec['title']) > 50 else rec['title'],
                "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©": rec.get('priority', 'Ù…ØªÙˆØ³Ø·Ø©'),
                "Ø§Ù„Ù…Ù‡Ù„Ø© (Ø£ÙŠØ§Ù…)": rec['due_in_days'],
                "Ø§Ù„Ø­Ø§Ù„Ø©": rec.get('status', 'Ø¬Ø¯ÙŠØ¯'),
                "Ø§Ù„Ù†ÙˆØ¹": rec.get('severity', 'info')
            })
        
        if actions_data:
            df_actions = pd.DataFrame(actions_data)
            st.dataframe(
                df_actions,
                use_container_width=True,
                column_config={
                    "Ø§Ù„Ù†ÙˆØ¹": st.column_config.SelectboxColumn(
                        "Ø§Ù„Ù†ÙˆØ¹",
                        options=["error", "warning", "success", "info"],
                        format_func=lambda x: {"error": "ğŸš¨ Ø­Ø±Ø¬Ø©", "warning": "âš ï¸ ØªØ­Ø°ÙŠØ±ÙŠØ©", 
                                              "success": "âœ… Ø¬ÙŠØ¯Ø©", "info": "â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØ©"}.get(x, x)
                    )
                    }
            )
    
    # Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØªÙˆØµÙŠØ§Øª", type="primary"):
            # Ø­ÙØ¸ Ø§Ù„ØªÙˆØµÙŠØ§Øª
            system = TransformerRecommendationSystem()
            if system.save_recommendations_state(recommendations):
                st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø¬Ø§Ø­!")
            else:
                st.error("ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙˆØµÙŠØ§Øª")
    
    with col2:
        if st.button("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"):
            st.info("Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„...")
    
    with col3:
        if st.button("ğŸ“§ Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„ÙØ±ÙŠÙ‚"):
            st.info("Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø®ØªØµ...")


def generate_enhanced_recommendations(loads_df, transformer_info, selected_transformer_id=None):
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø·ÙˆØ±Ø©"""
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙˆØµÙŠØ§Øª
    system = TransformerRecommendationSystem()
    
    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©
    recommendations, feeder_analyses, capacity_analysis, predictions = system.generate_comprehensive_recommendations(
        loads_df, transformer_info, selected_transformer_id
    )
    
    # Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©
    if feeder_analyses:
        st.subheader("ğŸ”Œ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ† Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
        for feeder_name, analysis in feeder_analyses.items():
            with st.expander(f"Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} - {analysis['current_status']}"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:** {analysis['current_status']}")
                    st.write(f"**Ø§Ù„Ù†Ù…Ø· Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ:** {analysis['historical_pattern']}")
                
                with col2:
                    st.write("**Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ:**")
                    for season, status in analysis['seasonal_behavior'].items():
                        status_icon = "âœ…" if status == "Ù…ØªØ²Ù†Ø©" else "âš ï¸"
                        st.write(f"{status_icon} {season}: {status}")
    
    if capacity_analysis['seasonal_loads']:
        st.subheader("âš¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¹Ø© Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
        for season, data in capacity_analysis['seasonal_loads'].items():
            with st.expander(f"ÙØµÙ„ {season}"):
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ù…ÙˆÙ„Ø©", f"{data['average']:.1f} KVA")
                    st.metric("Ø£Ù‚ØµÙ‰ Ø­Ù…ÙˆÙ„Ø©", f"{data['maximum']:.1f} KVA")
                with col2:
                    st.metric("Ù†Ø³Ø¨Ø© Ø§Ù„Ø§Ø³ØªØºÙ„Ø§Ù„ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©", f"{data['utilization']:.1f}%")
                    st.metric("Ø£Ù‚ØµÙ‰ Ù†Ø³Ø¨Ø© Ø§Ø³ØªØºÙ„Ø§Ù„", f"{data['max_utilization']:.1f}%")
    
    if predictions:
        st.subheader("ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª")
        pred_data = []
        for period, pred in predictions.items():
            pred_data.append({
                "Ø§Ù„ÙØªØ±Ø©": period,
                "Ø§Ù„Ø­Ù…ÙˆÙ„Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©": f"{pred['predicted_load']:.1f} KVA",
                "Ù†Ø³Ø¨Ø© Ø§Ù„Ø§Ø³ØªØºÙ„Ø§Ù„": f"{pred['utilization']:.1f}%",
                "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±": pred['risk_level']
            })
        
        if pred_data:
            st.dataframe(pd.DataFrame(pred_data), use_container_width=True)
    
    # Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª
    st.subheader("ğŸ“‹ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©")
    display_enhanced_recommendations(recommendations, feeder_analyses, capacity_analysis, predictions)
    
    return recommendations, feeder_analyses, capacity_analysis, predictions


def create_sample_data():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ø¹Ø±Ø¶"""
    np.random.seed(42)
    
    dates = pd.date_range('2022-01-01', '2023-12-31', freq='M')
    feeders = ['Ø´Ù…Ø§Ù„ÙŠ', 'Ø¬Ù†ÙˆØ¨ÙŠ', 'Ø´Ø±Ù‚ÙŠ', 'ØºØ±Ø¨ÙŠ']
    
    data = []
    for date in dates:
        for feeder in feeders:
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† Ù…ÙˆØ³Ù…ÙŠ
            season = "Ø´ØªÙˆÙŠ" if date.month in [12, 1, 2, 3] else "ØµÙŠÙÙŠ"
            
            base_current = 30 if season == "Ø´ØªÙˆÙŠ" else 20
            
            # Ø¥Ø¶Ø§ÙØ© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†
            if feeder == "Ø´Ù…Ø§Ù„ÙŠ" and season == "Ø´ØªÙˆÙŠ":
                ir = base_current + np.random.normal(10, 5)
                is_val = base_current + np.random.normal(-5, 3)
                it = base_current + np.random.normal(0, 2)
            elif feeder == "ØºØ±Ø¨ÙŠ":
                ir = base_current + np.random.normal(8, 4)
                is_val = base_current + np.random.normal(8, 4)
                it = base_current + np.random.normal(-10, 3)
            else:
                ir = base_current + np.random.normal(0, 3)
                is_val = base_current + np.random.normal(0, 3)
                it = base_current + np.random.normal(0, 3)
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙˆØ¬Ø¨Ø©
            ir = max(5, ir)
            is_val = max(5, is_val)
            it = max(5, it)
            
            data.append({
                'Ø±Ù‚Ù… Ø§Ù„ØªÙƒÙ„ÙŠÙ': len(data) + 1,
                'Transformer_id': 1,
                'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': date,
                'Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚ÙŠØ§Ø³': season,
                'Ø§Ø³Ù…_Ø§Ù„Ù…Ø­ÙˆÙ„': 'Ù…Ø­ÙˆÙ„ ØªØ¬Ø±ÙŠØ¨ÙŠ 1',
                'Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©': feeder,
                'Ù‚Ø¯Ø±Ø©_Ø§Ù„Ø³ÙƒÙŠÙ†Ø©': 400,
                'Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± R': int(ir),
                'Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± S': int(is_val),
                'Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± T': int(it),
                'Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± N': int(abs(ir - is_val - it)),
                'Ø§Ù„Ø¬Ù‡Ø¯ Ø¨ÙŠÙ† Ø§Ù„ÙØ§Ø²Ø§Øª RS': 400,
                'Ø§Ù„Ø¬Ù‡Ø¯ Ø¨ÙŠÙ† Ø§Ù„ÙØ§Ø²Ø§Øª RT': 400,
                'Ø§Ù„Ø¬Ù‡Ø¯ Ø¨ÙŠÙ† Ø§Ù„ÙØ§Ø²Ø§Øª ST': 400,
                'Ø§Ù„Ø¬Ù‡Ø¯ Ø¨ÙŠÙ† Ø§Ù„ÙØ§Ø²Ø§Øª RN': 230,
                'Ø§Ù„Ø¬Ù‡Ø¯ Ø¨ÙŠÙ† Ø§Ù„ÙØ§Ø²Ø§Øª SN': 230,
                'Ø§Ù„Ø¬Ù‡Ø¯ Ø¨ÙŠÙ† Ø§Ù„ÙØ§Ø²Ø§Øª TN': 230
            })
    
    return pd.DataFrame(data)


def load_and_process_data(uploaded_files):
    """ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©"""
    all_data = []
    
    for file in uploaded_files:
        try:
            if file.name.endswith('.csv'):
                df = pd.read_csv(file, encoding="cp1256")
            else:
                df = pd.read_excel(file)
            
            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØµØ¯Ø±
            df['Ù…ØµØ¯Ø±_Ø§Ù„Ù…Ù„Ù'] = file.name
            all_data.append(df)
            
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {file.name}: {str(e)}")
            continue
    
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        return combined_df
    else:
        return None


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…"""
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
    st.set_page_config(
        page_title="Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©",
        page_icon="âš¡",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.title("âš¡ Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    st.markdown("---")

    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    st.sidebar.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    uploaded_files = st.sidebar.file_uploader(
        "ğŸ“ ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        type=['csv', 'xlsx'],
        accept_multiple_files=True,
        help="Ø§Ø®ØªØ± Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (CSV Ø£Ùˆ Excel)"
    )

    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„
    st.sidebar.subheader("ğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„")
    transformer_capacity = st.sidebar.number_input(
        "Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„ (KVA)",
        min_value=100,
        max_value=5000,
        value=500,
        step=50
    )

    transformer_id = st.sidebar.number_input(
        "Ø±Ù‚Ù… Ø§Ù„Ù…Ø­ÙˆÙ„ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)",
        min_value=1,
        max_value=1000,
        value=1,
        help="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª"
    )

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
    st.sidebar.subheader("ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©")
    analysis_mode = st.sidebar.selectbox(
        "Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„",
        ["Ø´Ø§Ù…Ù„", "Ù…ÙˆØ³Ù…ÙŠ ÙÙ‚Ø·", "Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ† ÙÙ‚Ø·", "Ø§Ù„Ø³Ø¹Ø© ÙÙ‚Ø·"],
        help="Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"
    )

    imbalance_threshold = st.sidebar.slider(
        "Ø­Ø¯ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†",
        min_value=0.1,
        max_value=0.5,
        value=0.2,
        step=0.05,
        help="Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ø³ÙƒÙŠÙ†Ø© ØºÙŠØ± Ù…ØªØ²Ù†Ø©"
    )

    # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    if uploaded_files:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
            loads_df = load_and_process_data(uploaded_files)
            
        if loads_df is not None:
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(loads_df)} Ø³Ø¬Ù„ Ù…Ù† {len(uploaded_files)} Ù…Ù„Ù")
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª", len(loads_df))
            with col2:
                unique_transformers = loads_df['Transformer_id'].nunique() if 'Transformer_id' in loads_df.columns else 1
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª", unique_transformers)
            with col3:
                unique_feeders = loads_df['Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©'].nunique() if 'Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©' in loads_df.columns else 0
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†", unique_feeders)
            with col4:
                date_range = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                if 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³' in loads_df.columns:
                    loads_df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'] = pd.to_datetime(loads_df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], errors='coerce')
                    if not loads_df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'].isna().all():
                        min_date = loads_df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'].min()
                        max_date = loads_df['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'].max()
                        date_range = f"{min_date.strftime('%Y-%m')} - {max_date.strftime('%Y-%m')}"
                st.metric("Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©", date_range)
            
            # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with st.expander("ğŸ‘ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", expanded=False):
                st.dataframe(loads_df.head(10), use_container_width=True)
        
        else:
            st.error("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙŠØºØ© Ø§Ù„Ù…Ù„ÙØ§Øª.")
            loads_df = None

    else:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        st.info("ğŸ“ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ø¹Ø±Ø¶.")
        
        if st.button("ğŸ² Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©"):
            with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©..."):
                loads_df = create_sample_data()
            st.success("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª", len(loads_df))
            with col2:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª", 1)
            with col3:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†", 4)
            with col4:
                st.metric("Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©", "2022-2023")
                
            with st.expander("ğŸ‘ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©", expanded=False):
                st.dataframe(loads_df.head(10), use_container_width=True)
        else:
            loads_df = None

    # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
    if loads_df is not None and not loads_df.empty:
        
        st.markdown("---")
        st.header("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„")
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„
        transformer_info = {'Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„ KVA': transformer_capacity}
        
        # Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„", type="primary", use_container_width=True):
                st.session_state['run_analysis'] = True
                st.session_state['analysis_type'] = 'Ø´Ø§Ù…Ù„'
        
        with col2:
            if st.button("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹", use_container_width=True):
                st.session_state['run_analysis'] = True
                st.session_state['analysis_type'] = 'Ø³Ø±ÙŠØ¹'
        
        with col3:
            if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ†", use_container_width=True):
                st.session_state['run_analysis'] = False
                st.rerun()
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        if st.session_state.get('run_analysis', False):
            
            st.markdown("---")
            
            # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                status_text.text("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
                progress_bar.progress(20)
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙˆØµÙŠØ§Øª
                system = TransformerRecommendationSystem()
                system.imbalance_threshold = imbalance_threshold
                
                # Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                status_text.text("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
                progress_bar.progress(40)
                
                # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                processed_df = system.prepare_data(loads_df.copy())
                
                # Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
                status_text.text("ğŸ“‹ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª...")
                progress_bar.progress(60)
                
                recommendations, feeder_analyses, capacity_analysis, predictions = system.generate_comprehensive_recommendations(
                    processed_df, 
                    transformer_info, 
                    transformer_id if transformer_id else None
                )
                
                # Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
                status_text.text("ğŸ“Š Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©...")
                progress_bar.progress(80)
                
                visualizations = system.create_data_visualization(processed_df)
                
                # Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                status_text.text("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
                progress_bar.progress(100)
                
                # Ø¥Ø®ÙØ§Ø¡ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
                progress_bar.empty()
                status_text.empty()
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                st.success("ğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
                
                # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
                st.subheader("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø³Ø±ÙŠØ¹Ø©")
                
                error_count = len([r for r in recommendations if r.get('severity') == 'error'])
                warning_count = len([r for r in recommendations if r.get('severity') == 'warning'])
                success_count = len([r for r in recommendations if r.get('severity') == 'success'])
                info_count = len([r for r in recommendations if r.get('severity') == 'info'])
                
                col1, col2, col3, col4, col5 = st.columns(5)
                
                with col1:
                    st.metric(
                        "ğŸš¨ Ù…Ø´Ø§ÙƒÙ„ Ø­Ø±Ø¬Ø©",
                        error_count,
                        delta=f"-{error_count}" if error_count > 0 else None,
                        delta_color="inverse"
                    )
                
                with col2:
                    st.metric(
                        "âš ï¸ ØªØ­Ø°ÙŠØ±Ø§Øª", 
                        warning_count,
                        delta=f"-{warning_count}" if warning_count > 0 else None,
                        delta_color="inverse"
                    )
                
                with col3:
                    st.metric("âœ… Ø­Ø§Ù„Ø§Øª Ø¬ÙŠØ¯Ø©", success_count)
                
                with col4:
                    st.metric("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", info_count)
                
                with col5:
                    st.metric("ğŸ“‹ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª", len(recommendations))
                
                # Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ù„Ø¹Ø±Ø¶
                tab1, tab2, tab3, tab4 = st.tabs([
                    "ğŸ“‹ Ø§Ù„ØªÙˆØµÙŠØ§Øª",
                    "ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ", 
                    "ğŸ“ˆ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©",
                    "ğŸ“„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„"
                ])
                
                with tab1:
                    st.header("ğŸ“‹ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©")
                    display_enhanced_recommendations(recommendations, feeder_analyses, capacity_analysis, predictions)
                
                with tab2:
                    st.header("ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†
                    if feeder_analyses:
                        st.subheader("ğŸ”Œ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†")
                        
                        for feeder_name, analysis in feeder_analyses.items():
                            # ØªØ­Ø¯ÙŠØ¯ Ù„ÙˆÙ† Ø§Ù„Ø­Ø§Ù„Ø©
                            status_color = {
                                'Ø¬ÙŠØ¯Ø©': 'ğŸŸ¢',
                                'ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ù‚Ø¨Ø©': 'ğŸŸ¡', 
                                'Ø³ÙŠØ¦Ø©': 'ğŸ”´'
                            }.get(analysis['current_status'], 'âšª')
                            
                            with st.expander(f"{status_color} Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {feeder_name} - {analysis['current_status']}", expanded=analysis['current_status'] != 'Ø¬ÙŠØ¯Ø©'):
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.markdown("**ğŸ“Š Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©**")
                                    st.info(f"Ø§Ù„Ø­Ø§Ù„Ø©: {analysis['current_status']}")
                                    st.info(f"Ø§Ù„Ù†Ù…Ø· Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ: {analysis['historical_pattern']}")
                                    st.info(f"Ø§Ù„Ø§ØªØ¬Ø§Ù‡: {analysis['trend']}")
                                
                                with col2:
                                    st.markdown("**ğŸŒ¡ï¸ Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ**")
                                    for season, status in analysis['seasonal_behavior'].items():
                                        status_icon = "âœ…" if status == "Ù…ØªØ²Ù†Ø©" else "âš ï¸"
                                        st.write(f"{status_icon} **{season}:** {status}")
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¹Ø©
                    if capacity_analysis and capacity_analysis['seasonal_loads']:
                        st.subheader("âš¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¹Ø©")
                        
                        for season, data in capacity_analysis['seasonal_loads'].items():
                            with st.expander(f"ğŸŒ¡ï¸ ÙØµÙ„ {season}", expanded=data['max_utilization'] > 90):
                                
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric(
                                        "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ù…ÙˆÙ„Ø©", 
                                        f"{data['average']:.1f} KVA",
                                        delta=f"{data['utilization']:.1f}%" if data['utilization'] < 100 else None,
                                        delta_color="normal" if data['utilization'] < 85 else "inverse"
                                    )
                                
                                with col2:
                                    st.metric(
                                        "Ø£Ù‚ØµÙ‰ Ø­Ù…ÙˆÙ„Ø©", 
                                        f"{data['maximum']:.1f} KVA",
                                        delta=f"{data['max_utilization']:.1f}%" if data['max_utilization'] < 100 else f"+{data['max_utilization']-100:.1f}%",
                                        delta_color="normal" if data['max_utilization'] < 100 else "inverse"
                                    )
                                
                                with col3:
                                    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ¶Ø¹
                                    if data['max_utilization'] > 100:
                                        st.error("ğŸš¨ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø³Ø¹Ø©")
                                    elif data['max_utilization'] > 85:
                                        st.warning("âš ï¸ Ø§Ù‚ØªØ±Ø§Ø¨ Ù…Ù† Ø§Ù„Ø³Ø¹Ø©")
                                    elif data['utilization'] < 30:
                                        st.info("ğŸ’¡ Ø§Ø³ØªØºÙ„Ø§Ù„ Ù…Ù†Ø®ÙØ¶")
                                    else:
                                        st.success("âœ… Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©")
                    
                    # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠ
                    if predictions:
                        st.subheader("ğŸ”® Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠ")
                        
                        pred_df_data = []
                        for period, pred in predictions.items():
                            risk_color = {
                                "Ø¢Ù…Ù†": "ğŸŸ¢",
                                "Ù…Ù†Ø®ÙØ¶": "ğŸŸ¡", 
                                "Ù…ØªÙˆØ³Ø·": "ğŸŸ ",
                                "Ø¹Ø§Ù„ÙŠ": "ğŸ”´",
                                "Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹": "ğŸš¨"
                            }.get(pred['risk_level'], "âšª")
                            
                            pred_df_data.append({
                                "Ø§Ù„ÙØªØ±Ø©": period,
                                "Ø§Ù„Ø­Ù…ÙˆÙ„Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (KVA)": f"{pred['predicted_load']:.1f}",
                                "Ù†Ø³Ø¨Ø© Ø§Ù„Ø§Ø³ØªØºÙ„Ø§Ù„ (%)": f"{pred['utilization']:.1f}",
                                "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±": f"{risk_color} {pred['risk_level']}"
                            })
                        
                        if pred_df_data:
                            pred_df = pd.DataFrame(pred_df_data)
                            st.dataframe(pred_df, use_container_width=True)
                            
                            # ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                            high_risk_predictions = [p for p in predictions.values() if p['risk_level'] in ['Ø¹Ø§Ù„ÙŠ', 'Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹']]
                            if high_risk_predictions:
                                st.error(f"âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(high_risk_predictions)} ØªÙˆÙ‚Ø¹ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù…Ø®Ø§Ø·Ø±!")
                
                with tab3:
                    st.header("ğŸ“ˆ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©")
                    
                    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø³ÙƒÙŠÙ†Ø© Ù„Ù„Ø¹Ø±Ø¶
                    selected_feeder = st.selectbox(
                        "Ø§Ø®ØªØ± Ø§Ù„Ø³ÙƒÙŠÙ†Ø© Ù„Ù„Ø¹Ø±Ø¶:",
                        ['Ø§Ù„ÙƒÙ„'] + list(processed_df['Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©'].unique()) if 'Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©' in processed_df.columns else ['Ø§Ù„ÙƒÙ„'],
                        key="viz_feeder_select"
                    )
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
                    if selected_feeder != 'Ø§Ù„ÙƒÙ„':
                        viz_data = processed_df[processed_df['Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©'] == selected_feeder]
                        viz_title_suffix = f"- Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {selected_feeder}"
                    else:
                        viz_data = processed_df
                        viz_title_suffix = "- Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†"
                    
                    if not viz_data.empty:
                        
                        # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†
                        st.subheader(f"ğŸ“Š ØªØ·ÙˆØ± Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† {viz_title_suffix}")
                        
                        fig_imbalance = px.line(
                            viz_data,
                            x='ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³',
                            y='Imbalance',
                            color='Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©' if selected_feeder == 'Ø§Ù„ÙƒÙ„' else None,
                            title=f'ØªØ·ÙˆØ± Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† {viz_title_suffix}',
                            labels={'Imbalance': 'Ù†Ø³Ø¨Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': 'Ø§Ù„ØªØ§Ø±ÙŠØ®'}
                        )
                        
                        # Ø¥Ø¶Ø§ÙØ© Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ø±Ø¬Ø¹
                        fig_imbalance.add_hline(
                            y=imbalance_threshold, 
                            line_dash="dash", 
                            line_color="orange",
                            annotation_text=f"Ø­Ø¯ Ø§Ù„ØªØ­Ø°ÙŠØ± ({imbalance_threshold})"
                        )
                        fig_imbalance.add_hline(
                            y=system.high_imbalance_threshold, 
                            line_dash="dash", 
                            line_color="red",
                            annotation_text=f"Ø­Ø¯ Ø§Ù„Ø®Ø·Ø± ({system.high_imbalance_threshold})"
                        )
                        
                        fig_imbalance.update_layout(height=500)
                        st.plotly_chart(fig_imbalance, use_container_width=True)
                        
                        # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø£Ø­Ù…Ø§Ù„
                        st.subheader(f"âš¡ ØªØ·ÙˆØ± Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† {viz_title_suffix}")
                        
                        fig_load = px.line(
                            viz_data,
                            x='ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³',
                            y='Load_kVA',
                            color='Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©' if selected_feeder == 'Ø§Ù„ÙƒÙ„' else None,
                            title=f'ØªØ·ÙˆØ± Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† {viz_title_suffix}',
                            labels={'Load_kVA': 'Ø§Ù„Ø­Ù…Ù„ (KVA)', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': 'Ø§Ù„ØªØ§Ø±ÙŠØ®'}
                        )
                        
                        # Ø¥Ø¶Ø§ÙØ© Ø®Ø· Ø§Ù„Ø³Ø¹Ø©
                        fig_load.add_hline(
                            y=transformer_capacity,
                            line_dash="dash",
                            line_color="red",
                            annotation_text=f"Ø³Ø¹Ø© Ø§Ù„Ù…Ø­ÙˆÙ„ ({transformer_capacity} KVA)"
                        )
                        
                        fig_load.update_layout(height=500)
                        st.plotly_chart(fig_load, use_container_width=True)
                        
                        # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø© (Ù„Ù„Ø³ÙƒÙŠÙ†Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·)
                        if selected_feeder != 'Ø§Ù„ÙƒÙ„':
                            st.subheader(f"ğŸ”Œ ØªØ·ÙˆØ± Ø§Ù„ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {selected_feeder}")
                            
                            # ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠØ§Ø±Ø§Øª
                            currents_data = []
                            for _, row in viz_data.iterrows():
                                try:
                                    ir = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± R']).replace(',', '.'))
                                    is_val = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± S']).replace(',', '.'))
                                    it = float(str(row['Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙŠØ§Ø± T']).replace(',', '.'))
                                    
                                    currents_data.extend([
                                        {'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': row['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], 'Ø§Ù„ÙØ§Ø²': 'R', 'Ø§Ù„ØªÙŠØ§Ø±': ir},
                                        {'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': row['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], 'Ø§Ù„ÙØ§Ø²': 'S', 'Ø§Ù„ØªÙŠØ§Ø±': is_val},
                                        {'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': row['ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³'], 'Ø§Ù„ÙØ§Ø²': 'T', 'Ø§Ù„ØªÙŠØ§Ø±': it}
                                    ])
                                except:
                                    continue
                            
                            if currents_data:
                                currents_df = pd.DataFrame(currents_data)
                                fig_phases = px.line(
                                    currents_df,
                                    x='ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³',
                                    y='Ø§Ù„ØªÙŠØ§Ø±',
                                    color='Ø§Ù„ÙØ§Ø²',
                                    title=f'ØªØ·ÙˆØ± Ø§Ù„ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø© - Ø§Ù„Ø³ÙƒÙŠÙ†Ø© {selected_feeder}',
                                    labels={'Ø§Ù„ØªÙŠØ§Ø±': 'Ø§Ù„ØªÙŠØ§Ø± (Ø£Ù…Ø¨ÙŠØ±)', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚ÙŠØ§Ø³': 'Ø§Ù„ØªØ§Ø±ÙŠØ®'}
                                )
                                fig_phases.update_layout(height=500)
                                st.plotly_chart(fig_phases, use_container_width=True)
                        
                        # Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # ØªÙˆØ²ÙŠØ¹ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†
                            st.subheader("ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†")
                            fig_hist = px.histogram(
                                viz_data,
                                x='Imbalance',
                                color='Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©' if selected_feeder == 'Ø§Ù„ÙƒÙ„' else None,
                                title='ØªÙˆØ²ÙŠØ¹ Ù‚ÙŠÙ… Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†',
                                labels={'Imbalance': 'Ù†Ø³Ø¨Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†', 'count': 'Ø§Ù„ØªÙƒØ±Ø§Ø±'}
                            )
                            st.plotly_chart(fig_hist, use_container_width=True)
                        
                        with col2:
                            # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©
                            st.subheader("ğŸŒ¡ï¸ Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©")
                            if 'Ø§Ù„Ù…ÙˆØ³Ù…' in viz_data.columns:
                                seasonal_avg = viz_data.groupby(['Ø§Ù„Ù…ÙˆØ³Ù…', 'Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©'])['Load_kVA'].mean().reset_index() if selected_feeder == 'Ø§Ù„ÙƒÙ„' else viz_data.groupby('Ø§Ù„Ù…ÙˆØ³Ù…')['Load_kVA'].mean().reset_index()
                                
                                fig_seasonal = px.bar(
                                    seasonal_avg,
                                    x='Ø§Ù„Ù…ÙˆØ³Ù…',
                                    y='Load_kVA',
                                    color='Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©' if selected_feeder == 'Ø§Ù„ÙƒÙ„' and 'Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©' in seasonal_avg.columns else None,
                                    title='Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø­Ù…Ø§Ù„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©',
                                    labels={'Load_kVA': 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ù…Ù„ (KVA)', 'Ø§Ù„Ù…ÙˆØ³Ù…': 'Ø§Ù„Ù…ÙˆØ³Ù…'}
                                )
                                st.plotly_chart(fig_seasonal, use_container_width=True)
                
                with tab4:
                    st.header("ğŸ“„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„")
                    
                    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ±
                    st.markdown(f"""
                    ### ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ±
                    
                    - **ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                    - **Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ù…Ø­Ù„Ù„:** {transformer_id if transformer_id else 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª'}
                    - **Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„:** {transformer_capacity} KVA
                    - **Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„:** {st.session_state.get('analysis_type', 'Ø´Ø§Ù…Ù„')}
                    - **Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª:** {len(processed_df)}
                    - **Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©:** {date_range if 'date_range' in locals() else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}
                    """)
                    
                    # Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ
                    executive_summary = next((r for r in recommendations if 'Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ' in r['title']), None)
                    if executive_summary:
                        st.markdown("### ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ")
                        st.markdown(f"**Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ù…:** {executive_summary.get('message', '')}")
                        
                        if 'statistics' in executive_summary:
                            stats = executive_summary['statistics']
                            st.markdown(f"""
                            **Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:**
                            - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {stats.get('total_recommendations', 0)}
                            - Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø­Ø±Ø¬Ø©: {stats.get('critical', 0)}
                            - Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª: {stats.get('warnings', 0)}
                            - Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: {stats.get('overall_status', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
                            """)
                    
                    # ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ±
                    st.markdown("---")
                    st.subheader("ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ±")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if st.button("ğŸ“Š ØªØµØ¯ÙŠØ± Excel", use_container_width=True):
                            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel
                            output = io.BytesIO()
                            with pd.ExcelWriter(output, engine='openpyxl',encoding="utf-8") as writer:
                                # ÙˆØ±Ù‚Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª
                                recs_data = []
                                for rec in recommendations:
                                    recs_data.append({
                                        'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†': rec['title'],
                                        'Ø§Ù„Ø±Ø³Ø§Ù„Ø©': rec['message'],
                                        'Ø§Ù„Ù†ÙˆØ¹': rec['severity'],
                                        'Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡': rec['action'],
                                        'Ø§Ù„Ù…Ù‡Ù„Ø©_Ø¨Ø§Ù„Ø£ÙŠØ§Ù…': rec['due_in_days'],
                                        'Ø§Ù„Ø­Ø§Ù„Ø©': rec.get('status', 'Ø¬Ø¯ÙŠØ¯'),
                                        'Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©': rec.get('priority', 'Ù…ØªÙˆØ³Ø·Ø©')
                                    })
                                pd.DataFrame(recs_data).to_excel(writer, sheet_name='Ø§Ù„ØªÙˆØµÙŠØ§Øª', index=False)
                                
                                # ÙˆØ±Ù‚Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                                processed_df.to_excel(writer, sheet_name='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª_Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©', index=False)
                                
                                # ÙˆØ±Ù‚Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†
                                if feeder_analyses:
                                    feeder_data = []
                                    for feeder, analysis in feeder_analyses.items():
                                        feeder_data.append({
                                            'Ø§Ù„Ø³ÙƒÙŠÙ†Ø©': feeder,
                                            'Ø§Ù„Ø­Ø§Ù„Ø©_Ø§Ù„Ø­Ø§Ù„ÙŠØ©': analysis['current_status'],
                                            'Ø§Ù„Ù†Ù…Ø·_Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ': analysis['historical_pattern'],
                                            'Ø§Ù„Ø§ØªØ¬Ø§Ù‡': analysis['trend']
                                        })
                                    pd.DataFrame(feeder_data).to_excel(writer, sheet_name='ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†', index=False)
                            
                            st.download_button(
                                label="ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Excel",
                                data=output.getvalue(),
                                file_name=f"transformer_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                    
                    with col2:
                        if st.button("ğŸ“„ ØªØµØ¯ÙŠØ± PDF", use_container_width=True):
                            st.info("ğŸ“„ Ø³ÙŠØªÙ… ØªÙˆÙÙŠØ± ØªØµØ¯ÙŠØ± PDF Ù‚Ø±ÙŠØ¨Ø§Ù‹")
                    
                    with col3:
                        if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø©", use_container_width=True):
                            if system.save_recommendations_state(recommendations):
                                st.success("ØªÙ… Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª!")
                            else:
                                st.error("ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª")
            
            except Exception as e:
                st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")
                st.exception(e)

    else:
        st.info("ğŸ“‚ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„.")
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…
        with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…", expanded=True):
            st.markdown("""
            ## ğŸ” Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            
            Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠÙˆÙØ± ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© ÙˆÙŠÙ‚Ø¯Ù… ØªÙˆØµÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù„Ù„ØµÙŠØ§Ù†Ø© ÙˆØ§Ù„ØªØ´ØºÙŠÙ„.
            
            ### âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
            
            - **ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„:** ØªØ­Ù„ÙŠÙ„ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†ØŒ Ø§Ù„Ø³Ø¹Ø©ØŒ ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ
            - **ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤:** ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
            - **ğŸ“‹ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ©:** ØªÙˆØµÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù…Ø¹ Ø®Ø·Ø· Ø¹Ù…Ù„ ÙˆÙ…ÙˆØ§Ø¹ÙŠØ¯ ØªÙ†ÙÙŠØ°
            - **ğŸ“ˆ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©:** Ø¹Ø±Ø¶ Ø¨ØµØ±ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
            - **ğŸ’¾ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø©:** ØªØªØ¨Ø¹ ÙˆØ­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©
            
            ### ğŸ“ ØµÙŠØº Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:
            - Ù…Ù„ÙØ§Øª CSV
            - Ù…Ù„ÙØ§Øª Excel (.xlsx, .xls)
            
            ### ğŸ¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„:
            1. **Ø´Ø§Ù…Ù„:** ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù…Ø­ÙˆÙ„
            2. **Ù…ÙˆØ³Ù…ÙŠ:** Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠ
            3. **Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†:** ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ø³ÙƒØ§ÙƒÙŠÙ†
            4. **Ø§Ù„Ø³Ø¹Ø©:** ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØºÙ„Ø§Ù„ Ø§Ù„Ø³Ø¹Ø© ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø²Ø§Ø¦Ø¯
            """)

    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ - Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©")
    st.sidebar.markdown("""
    - ğŸ“§ **Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ:** support@transformers.com
    - ğŸ“± **Ø§Ù„Ù‡Ø§ØªÙ:** +970-XXX-XXXX
    - ğŸŒ **Ø§Ù„Ù…ÙˆÙ‚Ø¹:** www.transformers-analysis.com
    """)

    st.sidebar.markdown("---")
    st.sidebar.caption("Â© 2024 Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©")
main()